---
title: "sentiment_analysis"
author: "GuillermoSchneider"
date: "2024-03-08"
output: html_document
---

```{r}
#install.packages("tidytext")
#install.packages("textdata")
#install.packages("tidyverse")
#install.packages("wordcloud")
library(tidytext)
library(textdata)
library(tidyverse)
library(wordcloud)

```

##https://www.tidytextmining.com/sentiment

### GRABBING SENTIMENT LABELED DICTIONARIES

**AFINN from Finn Ã…rup Nielsen**
```{r}
afinn <- get_sentiments("afinn")
```

**bing from Bing Liu and collaborators**
```{r}
bing <- get_sentiments("bing")
```

**nrc from Saif Mohammad and Peter Turney**
```{r}
nrc <- get_sentiments("nrc")
```

### SCRAPING THANKS TO LUCAS

**sample of 8000 posts from lucas**
```{r}
test_scrape <- read.csv("https://raw.githubusercontent.com/GuillermoCharlesSchneider/DATA-607/main/Project-3/test_scrape.csv")
```

**full 125k posts from lucas**
```{r}
full_scrape <- read.csv("https://raw.githubusercontent.com/riverar9/cuny-msds-project-3/main/part_2/reddit%20scrape.csv")
```


#UPDATED SKILLS

**Skills provided by jon:**
```{r}
Skills <- read.csv("https://raw.githubusercontent.com/GuillermoCharlesSchneider/DATA-607/main/Project-3/skills.csv")
```

**separate skills into single words, while still keeping the general skill bucket**
```{r}
Skills$word <- tolower(Skills$Skills)

Skills_single_word <- Skills %>%
  unnest_tokens(word, word)

Skills_single_word <- Skills_single_word[-c(4,9,10,11,20,21,22,23,25,28,31,40,41,42,43,46,48,50,55,57,62,65,67,71,72,75,80,83,84,92,99,136,140,141,146,147,148,150,151,152,153,154), ]
row.names(Skills_single_word) <- 1:nrow(Skills_single_word)

```

**TWO WORD SKILLS MERGED INTO ONE and trimmed (ex:data science -> datascience), multiple words per bucket. this is a stupid method, but i was too tired to figure out a new function, and i needed to look through them all anyway to see which needed to be combined and which didnt:**
```{r}
for(x in c(1,5,10,13,21,24,23,26,29,35,37,39,42,46,48,50,56,60,59,64,63,66,73,72,75,77,80,79,82,84,86,91,93,98,97,102,101,100,106,108,110)){
  Skills_single_word$word[x] <- paste(Skills_single_word$word[x],Skills_single_word$word[x+1],sep = "")
}

Skills_single_word <- Skills_single_word[-c(2,6,11,14,17,18,22,25,24,27,30,36,38,40,43,47,49,51,57,61,60,65,64,67,74,73,76,78,81,80,83,85,87,90,92,94,99,98,103,102,101,107,109,111), ]
row.names(Skills_single_word) <- 1:nrow(Skills_single_word)


```

```{r}
write.csv(Skills_single_word, "Updated_Skills.csv", row.names=FALSE)
```

## MERGED 2 WORD SKILLS (ex: data science -> datascience) IN SCRAPED REDDIT COMMENTS

###**TEST SCRAPE 8k**
```{r}
test_scrape$comment <- tolower(test_scrape$comment)
```

**test 8k data, once again im sure we could write a function, but ive already commited to this stupid copy paste, maybe one of you can make a:  gsub inputs(skills...), desired outputs (skills merged...)**
```{r}
test_scrape$comment <- gsub("data science", "datascience,",test_scrape$comment)
test_scrape$comment <- gsub("data analysis", "dataanalysis,",test_scrape$comment)
test_scrape$comment <- gsub("cloud databases", "clouddatabases",test_scrape$comment)
test_scrape$comment <- gsub("machine learning", "machinelearning",test_scrape$comment)
test_scrape$comment <- gsub("apache spark", "apachespark",test_scrape$comment)
test_scrape$comment <- gsub("pivot table", "pivottable",test_scrape$comment)
test_scrape$comment <- gsub("case studies", "casestudies",test_scrape$comment)
test_scrape$comment <- gsub("convolutional neuralnet works", "convolutionalneuralnetworks",test_scrape$comment)
test_scrape$comment <- gsub("data ethics", "dataethics",test_scrape$comment)
test_scrape$comment <- gsub("data collection", "datacollection,",test_scrape$comment)
test_scrape$comment <- gsub("data exploration", "dataexploration,",test_scrape$comment)
test_scrape$comment <- gsub("artificial intelligence", "artificialintelligence,",test_scrape$comment)
test_scrape$comment <- gsub("machine learning", "machinelearning,",test_scrape$comment)

#ive started to regret it about here
test_scrape$comment <- gsub("ask questions", "askquestions,",test_scrape$comment)
test_scrape$comment <- gsub("data driven", "datadriven",test_scrape$comment)
test_scrape$comment <- gsub("big data", "bigdata",test_scrape$comment)
test_scrape$comment <- gsub("descriptive statistics", "descriptivestatistics",test_scrape$comment)
test_scrape$comment <- gsub("recurrent neural network", "recurrentneuralnetwork",test_scrape$comment)
test_scrape$comment <- gsub("deep neural networks", "deepneuralnetworks",test_scrape$comment)
test_scrape$comment <- gsub("hyper parameter tuning", "hyperparametertuning",test_scrape$comment)
test_scrape$comment <- gsub("exploratory data analysis", "exploratorydataanalysis",test_scrape$comment)
test_scrape$comment <- gsub("neural network architecture", "neuralnetworkarchitecture",test_scrape$comment)
test_scrape$comment <- gsub("regression analysis", "regressionanalysis",test_scrape$comment)
test_scrape$comment <- gsub("data aggregation", "dataaggregation",test_scrape$comment)
test_scrape$comment <- gsub("deep learning", "deeplearning",test_scrape$comment)
test_scrape$comment <- gsub("data cleansing", "datacleansing",test_scrape$comment)
test_scrape$comment <- gsub("statistical hypothesis testing", "statisticalhypothesistesting",test_scrape$comment)
test_scrape$comment <- gsub("relational database management systems", "relationaldatabasemanagementsystems",test_scrape$comment)
test_scrape$comment <- gsub("information technology", "informationtechnology",test_scrape$comment)
test_scrape$comment <- gsub("data architecture", "dataarchitecture",test_scrape$comment)
test_scrape$comment <- gsub("process data", "processdata",test_scrape$comment)


```

**separate 8000 comments into single words**
```{r}
tidy_test_scrape <- test_scrape %>%
  unnest_tokens(word, comment)
```


```{r}
TEST <- tidy_test_scrape %>%
  left_join(afinn) 


TEST <- TEST %>%
  left_join(bing) 

```


```{r}
write.csv(tidy_test_scrape, "tidy_test_scrape_merged.csv", row.names=FALSE)
```

###**FULL SCRAPE**

**full_scrape TO LOWER CASE**
```{r}
full_scrape$comment <- tolower(full_scrape$comment)
```

**CLEANING TWO WORDS TO ONE. once again no function... zzz**
```{r}
full_scrape$comment <- gsub("data science", "datascience,",full_scrape$comment)
full_scrape$comment <- gsub("data analysis", "dataanalysis,",full_scrape$comment)
full_scrape$comment <- gsub("cloud databases", "clouddatabases",full_scrape$comment)
full_scrape$comment <- gsub("machine learning", "machinelearning",full_scrape$comment)
full_scrape$comment <- gsub("apache spark", "apachespark",full_scrape$comment)
full_scrape$comment <- gsub("pivot table", "pivottable",full_scrape$comment)
full_scrape$comment <- gsub("case studies", "casestudies",full_scrape$comment)
full_scrape$comment <- gsub("convolutional neuralnet works", "convolutionalneuralnetworks",full_scrape$comment)
full_scrape$comment <- gsub("data ethics", "dataethics",full_scrape$comment)
full_scrape$comment <- gsub("data collection", "datacollection,",full_scrape$comment)
full_scrape$comment <- gsub("data exploration", "dataexploration,",full_scrape$comment)
full_scrape$comment <- gsub("artificial intelligence", "artificialintelligence,",full_scrape$comment)
full_scrape$comment <- gsub("machine learning", "machinelearning,",full_scrape$comment)

#ive started to regret it about here
full_scrape$comment <- gsub("ask questions", "askquestions,",full_scrape$comment)
full_scrape$comment <- gsub("data driven", "datadriven",full_scrape$comment)
full_scrape$comment <- gsub("big data", "bigdata",full_scrape$comment)
full_scrape$comment <- gsub("descriptive statistics", "descriptivestatistics",full_scrape$comment)
full_scrape$comment <- gsub("recurrent neural network", "recurrentneuralnetwork",full_scrape$comment)
full_scrape$comment <- gsub("deep neural networks", "deepneuralnetworks",full_scrape$comment)
full_scrape$comment <- gsub("hyper parameter tuning", "hyperparametertuning",full_scrape$comment)
full_scrape$comment <- gsub("exploratory data analysis", "exploratorydataanalysis",full_scrape$comment)
full_scrape$comment <- gsub("neural network architecture", "neuralnetworkarchitecture",full_scrape$comment)
full_scrape$comment <- gsub("regression analysis", "regressionanalysis",full_scrape$comment)
full_scrape$comment <- gsub("data aggregation", "dataaggregation",full_scrape$comment)
full_scrape$comment <- gsub("deep learning", "deeplearning",full_scrape$comment)
full_scrape$comment <- gsub("data cleansing", "datacleansing",full_scrape$comment)
full_scrape$comment <- gsub("statistical hypothesis testing", "statisticalhypothesistesting",full_scrape$comment)
full_scrape$comment <- gsub("relational database management systems", "relationaldatabasemanagementsystems",full_scrape$comment)
full_scrape$comment <- gsub("information technology", "informationtechnology",full_scrape$comment)
full_scrape$comment <- gsub("data architecture", "dataarchitecture",full_scrape$comment)
full_scrape$comment <- gsub("process data", "processdata",full_scrape$comment)
```





**separate 125k comments into single words**
```{r}
tidy_full_scrape <- full_scrape %>%
  unnest_tokens(word, comment)
```


```{r}
sentiment_tidy_merged_full_scrape <- tidy_full_scrape %>%
  left_join(afinn) 


sentiment_tidy_merged_full_scrape <- sentiment_tidy_merged_full_scrape %>%
  left_join(bing) 

```





CLEANED TIDIED DATASET WITH MERGED WORDS
```{r}
write.csv(sentiment_tidy_merged_full_scrape, "tidy_full_scrape_merged_sentiments.csv", row.names=FALSE)
```


**count of single word Skills words in the tidied scape:**
```{r}
#8000 comments
tidy_test_scrape %>%
  inner_join(Skills_single_word) %>%
  count(word, sort = TRUE)

#125k comments
tidy_full_scrape %>%
  inner_join(Skills_single_word) %>%
  count(word, sort = TRUE)
```


**joyful words from NRC:**
```{r}
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")
```

**count of joyful words in the tidied single word scrape, matching 1 to 1 words w inner join on "word" column:**
```{r}
tidy_test_scrape %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
```



**count of all single words**
```{r}
t <- tidy_scrape %>%
  count(word, sort = TRUE)
```


search through reddit comments, group the skills thatre are 2 words

skills one word
Search for comments that include those words
see what positive or negative words are around in those comments
score?
see which topics have more negative postive score?
weight it by the relevancy?



nrc from Saif Mohammad and Peter Turney -> word cloud


sentiment analysis over time, we have the reddit dates, positive minus negative

list the courses that we scraped

**????? idk i cant this stupid wordcloud to work atm, ill fix it at some pt**
```{r}
library(wordcloud)
w <- sort(rowSums(t), decreasing = TRUE)
set.seed(222)
wordcloud(word = word(w),
          freq = w,
          max.words = 150,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(5, 0.3),
          rot.per = 0.7)
```

